# ğŸ“Š AnÃ¡lisis Estructural Automatizado

Sistema de generaciÃ³n de reportes narrativos basados exclusivamente en datos observables del anÃ¡lisis de superficie digital.

## ğŸ¯ Objetivo

Generar anÃ¡lisis estructurados y audit-friendly que:
- âœ… No inventan datos
- âœ… Son compatibles con OpenAI/ChatGPT para post-procesamiento
- âœ… Funcionan en modo batch, API o Streamlit
- âœ… Son legalmente defendibles

## ğŸ“ Archivos

### `analisis_estructural.py`
MÃ³dulo principal con las funciones de generaciÃ³n de anÃ¡lisis:

```python
from analisis_estructural import (
    generar_analisis_estructural,  # Genera anÃ¡lisis de una fila
    procesar_csv,                  # Procesa CSV completo
    procesar_dataframe,            # Procesa DataFrame existente
    exportar_markdown,             # Exporta a .md
    exportar_txt                   # Exporta a .txt
)
```

### `ejemplo_analisis_estructural.py`
Script de ejemplo para uso desde lÃ­nea de comandos:

```bash
python ejemplo_analisis_estructural.py prospectscan_cruce_20260106.csv
```

Genera automÃ¡ticamente:
- `analisis_estructural_batch.txt`
- `analisis_estructural_batch.md`
- `analisis_estructural_batch.csv`

## ğŸš€ Uso

### 1. Desde lÃ­nea de comandos

```bash
# Procesar CSV
python analisis_estructural.py archivo.csv salida.csv

# Usar script de ejemplo completo
python ejemplo_analisis_estructural.py archivo.csv
```

### 2. Desde Python

```python
import pandas as pd
from analisis_estructural import procesar_dataframe, exportar_txt

# Cargar datos
df = pd.read_csv("prospectscan_cruce_20260106.csv")

# Generar anÃ¡lisis
resultados = procesar_dataframe(df)

# Exportar
exportar_txt(resultados, "analisis_batch.txt")

# Ver anÃ¡lisis individual
print(resultados[0]['analisis'])
```

### 3. Desde Streamlit (integrado)

En la aplicaciÃ³n Streamlit ([app_superficie.py](app_superficie.py)):

1. Ve al tab **"Pipeline Cruce"**
2. Carga tu Excel de ZoomInfo
3. Procesa los dominios
4. Haz clic en **"ğŸ“ Generar AnÃ¡lisis Estructural"**
5. Descarga en formato TXT o Markdown

## ğŸ“‹ Estructura del AnÃ¡lisis

Cada anÃ¡lisis incluye 7 secciones:

```
1. IDENTIFICACIÃ“N DE LA ORGANIZACIÃ“N
   - Empresa, dominio, paÃ­s, empleados, industria, ingresos

2. POSTURA DECLARADA DEL ENTORNO DIGITAL
   - Postura de identidad, exposiciÃ³n y general

3. SUPERFICIE DE CORREO ELECTRÃ“NICO
   - Proveedor, gateway, SPF, DMARC, mecanismos de envÃ­o

4. SUPERFICIE WEB
   - HTTPS, CDN/WAF, HSTS, CSP

5. SCORE Y PRIORIDAD
   - Score de seguridad, prioridad, score de oportunidad

6. NARRATIVA EXISTENTE
   - Factores positivos, negativos, talking points

7. INFORMACIÃ“N ECONÃ“MICA
   - Budget estimado (min/max)

CONCLUSIÃ“N
   - Resumen ejecutivo basado en datos observables
```

## ğŸ¤– IntegraciÃ³n con OpenAI/ChatGPT

El anÃ¡lisis generado puede ser enviado a modelos de lenguaje para:

### Post-procesamiento
```python
import openai

analisis_original = resultados[0]['analisis']

# Reformular para C-Level
response = openai.chat.completions.create(
    model="gpt-4",
    messages=[
        {
            "role": "system",
            "content": "Eres un analista de ciberseguridad. "
                      "Resume anÃ¡lisis tÃ©cnicos para comitÃ©s ejecutivos."
        },
        {
            "role": "user",
            "content": f"Resume este anÃ¡lisis para C-Level:\n\n{analisis_original}"
        }
    ]
)

print(response.choices[0].message.content)
```

### Casos de uso
- **ReformulaciÃ³n por audiencia**: C-Level, tÃ©cnico, comercial
- **Resumen ejecutivo**: Extraer solo lo crÃ­tico
- **AuditorÃ­a de consistencia**: Verificar coherencia del anÃ¡lisis
- **GeneraciÃ³n de recomendaciones**: Sugerencias accionables

## ğŸ”§ ConfiguraciÃ³n

No requiere configuraciÃ³n adicional. Usa las mismas columnas del DataFrame de ProspectScan:

```python
# Columnas requeridas (usa las que existan)
COLUMNAS = [
    'empresa', 'dominio', 'pais', 'empleados', 'industria', 'revenue',
    'postura_identidad', 'postura_exposicion', 'postura_general',
    'correo_proveedor', 'correo_gateway', 'correo_envio',
    'spf_estado', 'dmarc_estado',
    'https_estado', 'cdn_waf', 'hsts', 'csp',
    'score', 'prioridad', 'prioridad_num', 'score_oportunidad',
    'factores_positivos', 'factores_negativos', 'talking_points',
    'budget_min', 'budget_max', 'dominio_antiguedad'
]
```

## ğŸ“¤ Formatos de exportaciÃ³n

| Formato | DescripciÃ³n | Uso recomendado |
|---------|-------------|------------------|
| **TXT** | Texto plano con formato | RevisiÃ³n rÃ¡pida, email |
| **Markdown** | Formato Markdown con sintaxis | DocumentaciÃ³n, GitHub |
| **CSV** | Datos estructurados | AnÃ¡lisis masivo, Excel |

## âœ… CaracterÃ­sticas

### Audit-friendly
- No inventa datos
- Solo usa informaciÃ³n observable
- Valores faltantes se marcan como "No disponible"
- Trazabilidad completa

### Batch-ready
- Procesa mÃºltiples dominios en paralelo
- ExportaciÃ³n masiva en mÃºltiples formatos
- Compatible con scripts de automatizaciÃ³n

### Copilot-compatible
- CÃ³digo limpio y documentado
- Funciones modulares y reutilizables
- Sin dependencias externas complejas

### AUP-compatible
- AnÃ¡lisis basado en datos pÃºblicos observables
- Sin inferencias no autorizadas
- DiseÃ±o defensible legalmente

## ğŸ”„ Flujo de trabajo recomendado

```
1. Cargar CSV/Excel
   â””â”€â”€> procesar_csv() o procesar_dataframe()

2. Generar anÃ¡lisis
   â””â”€â”€> resultados = [{empresa, dominio, analisis}, ...]

3. Exportar segÃºn necesidad
   â”œâ”€â”€> exportar_txt() - Para revisiÃ³n
   â”œâ”€â”€> exportar_markdown() - Para documentaciÃ³n
   â””â”€â”€> DataFrame.to_csv() - Para anÃ¡lisis

4. (Opcional) Post-procesar con OpenAI
   â””â”€â”€> Reformular, resumir, auditar
```

## ğŸ“ Ejemplos avanzados

### Filtrar por prioridad antes de exportar
```python
df = pd.read_csv("prospectscan_cruce_20260106.csv")

# Solo crÃ­ticos y altos
df_filtrado = df[df['prioridad'].isin(['ğŸ”´ CrÃ­tica', 'ğŸŸ  Alta'])]

# Generar anÃ¡lisis solo de crÃ­ticos
resultados = procesar_dataframe(df_filtrado)
exportar_txt(resultados, "analisis_criticos.txt")
```

### IntegraciÃ³n con pipeline de CI/CD
```bash
#!/bin/bash
# pipeline.sh

# 1. Generar anÃ¡lisis
python analisis_estructural.py input.csv output.csv

# 2. Subir a storage
aws s3 cp analisis_batch.txt s3://bucket/reportes/

# 3. Notificar
curl -X POST webhook_url -d "AnÃ¡lisis completado"
```

### API REST simple
```python
from fastapi import FastAPI, UploadFile
from analisis_estructural import procesar_csv
import pandas as pd

app = FastAPI()

@app.post("/analizar")
async def analizar_csv(file: UploadFile):
    df = pd.read_csv(file.file)
    resultados = procesar_dataframe(df)
    return {"resultados": resultados}
```

## ğŸ“š Recursos adicionales

- [app_superficie.py](app_superficie.py) - IntegraciÃ³n Streamlit
- [db_cache.py](db_cache.py) - Cache de dominios
- [README.md](README.md) - DocumentaciÃ³n general

## ğŸ¤ Contribuciones

Este mÃ³dulo estÃ¡ diseÃ±ado para ser:
- **Extensible**: FÃ¡cil agregar nuevas secciones al anÃ¡lisis
- **Mantenible**: CÃ³digo limpio y documentado
- **Auditable**: Sin magic numbers ni lÃ³gica oculta

Para agregar nuevas secciones al anÃ¡lisis, edita `generar_analisis_estructural()` en [analisis_estructural.py](analisis_estructural.py).

## ğŸ“§ Soporte

Para dudas o reportar problemas, revisa:
1. El cÃ³digo en `analisis_estructural.py` (estÃ¡ bien documentado)
2. El script de ejemplo `ejemplo_analisis_estructural.py`
3. La integraciÃ³n en Streamlit (tab "Pipeline Cruce")
